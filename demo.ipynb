{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from diffusers import StableDiffusionPipeline, DPMSolverMultistepScheduler\n",
    "from diffusers.utils import make_image_grid\n",
    "from image_noiser import ImageNoiser\n",
    "import torch\n",
    "import open_clip\n",
    "from artifact_estimator.model import load_model, preprocess\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = StableDiffusionPipeline.from_pretrained(\"runwayml/stable-diffusion-v1-5\", torch_dtype=torch.float16).to('cuda')\n",
    "pipe.enable_sequential_cpu_offload()\n",
    "pipe.vae.enable_slicing()\n",
    "pipe.vae.enable_tiling()\n",
    "pipe.scheduler = DPMSolverMultistepScheduler.from_config(pipe.scheduler.config)\n",
    "\n",
    "image_noiser = ImageNoiser(sd_pipe=pipe) #It'll use pipe's components\n",
    "\n",
    "clip, _, preprocess_clip = open_clip.create_model_and_transforms('hf-hub:Outrun32/CLIP-ViT-B-16-noise-tuned')\n",
    "clip.to('cuda')\n",
    "\n",
    "mlp = load_model('artifact_estimator/models/artifact_estimator_openclip_vit_b_16.pth').to('cuda')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "artifacted = []\n",
    "PREDICTION_THRESHOLD = 3.0\n",
    "\n",
    "def latents_callback_prediction_with_removal(pipe, i, t, kwargs):\n",
    "    global artifacted\n",
    "    if i%10 == 0 and i > 0: #For now only steps 10 and 20, later should write a custom pipeline to remove images from batch\n",
    "        latents = kwargs['latents']\n",
    "        prompt_embeds = kwargs['prompt_embeds']\n",
    "        negative_prompt_embeds = kwargs['negative_prompt_embeds']\n",
    "        approximated_latents = image_noiser.approx_latents_batch(latents)\n",
    "        clip_latents = [clip.encode_image(preprocess_clip(approximated_latent).unsqueeze(0).to('cuda')) for approximated_latent in approximated_latents]\n",
    "        with torch.no_grad():\n",
    "            predictions = [mlp(preprocess(clip_latent)) for clip_latent in clip_latents]\n",
    "        for i, pred in enumerate(predictions):\n",
    "            if pred > PREDICTION_THRESHOLD:\n",
    "                if i not in artifacted:\n",
    "                    print('One of the images is artifacted, removing from batch!')\n",
    "                    artifacted.append(i)\n",
    "                # latents = torch.cat((latents[:i], latents[i+1:]))\n",
    "                # negative_prompt_embeds = torch.cat((negative_prompt_embeds[:i], negative_prompt_embeds[i+1:])) #Probably no way to remove image from batch without going into batch\n",
    "                # prompt_embeds = torch.cat([torch.cat((embed[:i], embed[i+1:])) for embed in prompt_embeds.chunk(2)])\n",
    "                # print(prompt_embeds.shape)\n",
    "            \n",
    "            \n",
    "    # kwargs[\"latents\"] = latents\n",
    "    # kwargs[\"propmt_embeds\"] = prompt_embeds\n",
    "    # kwargs[\"negative_prompt_embeds\"] = negative_prompt_embeds\n",
    "    return kwargs\n",
    "    # images.append(approximated_latents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_images = 4\n",
    "prompt = \"A photo of deformed doggo, extremely distorted, bad, artifacts, horrible\"\n",
    "images.clear()\n",
    "artifacted.clear()\n",
    "images = pipe(prompt, num_inference_steps=20, callback_on_step_end=latents_callback_prediction_with_removal,\n",
    "              num_images_per_prompt=num_images, callback_on_step_end_tensor_inputs=[\"latents\", \"prompt_embeds\", \"negative_prompt_embeds\"]).images\n",
    "final_images = [image for i, image in enumerate(images) if i not in artifacted]\n",
    "if len(final_images) > 0:\n",
    "    grid = make_image_grid(final_images, 1, len(final_images))\n",
    "else:\n",
    "    print(\"All images were artifacted\")\n",
    "grid"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "artifact-estimator",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
